<svelte:head>
	<title>Encyclopedia Disinformatica - SB.</title>
    <link rel="icon" href="{base}/images/articleaasil1.png" />
    <meta name="description" content="Encyclopedia Disinformatica Author: A++">
</svelte:head>

<script>
	import '../../../fonts.css';
	import '../../../styles.css';
    import '../generic-article.css'
	import { base } from '$app/paths';
</script>

<h1 class="articletitle">Encyclopedia Disinformatica</h1>

<div class="datebox">
    <h4>6th August, 2023</h4>
    <div class="bosx">
        <h4>By A++</h4>
        <img src="{base}/images/assil.jpg" alt="Hi there" />
    </div>
</div>

<h2>The Challenges and Choices of Protecting Information on the Internet
</h2>

<div class="flex">
    <img class="titleImg" src="{base}/images/articleaasil1.png" alt="Hi there" />
</div>

<h2>Introduction</h2>

<div class="quotebox">
    <h4 class="quote">
        “In the age of information, ignorance is a choice” <h3>- Donald Miller</h3>
    </h4>
</div>

<div class="paragraf">
<p>
    In the pre-Internet world, people believed that access to information was the alchemical cure for ignorance. That, almost poetically, if someone were to invent a portable, easily-viewable, ever-increasing library of information that a good chunk of the world's people can access, you would be able to defeat ignorance and cause intellectual advancement to leap forward.
</p>

<p>
    But there’s a catch: <i>ignorance</i> is a subjective term and varies from person to person depending on cultural background and beliefs. And this will always be the case, no matter what cognitive tweaking you do or the indoctrination campaign you run, it will never be implemented on a large enough scale to draw quantifiable effects. 
</p>

<p>
    And how are you going to tell a good percent of Internet users that their views on religion, politics, science, etcetera are '<i>misinformation</i>'? 
</p>

<p>
    In 1948, representatives from all over the world met to draft a famous document (now considered as being something of a meme) known as the <i>Universal Declaration of Human Rights</i>. The document includes a profusion of righteous principles that have been dishonoured multiple times every year since the documents’ drafting, but two particular Articles stand out from the rest - Articles 18 and 19:
</p>
<div class="quotebox">
    <h3 class="quote">
        Everyone has the right to freedom of thought, conscience and religion […] [and] to manifest his religion or belief in teaching, practice, worship and observance. 
    </h3>
    <h4>–  Article 18</h4>
    <h3 class="quote">
        Everyone has the right to freedom of opinion and expression; this right includes freedom to hold opinions […] and to seek, receive and impart information and ideas through any media and regardless of frontiers. 
    </h3>
    <h4>–  Article 19</h4>
</div>

<p>
    These promises to Humanity were rarely upheld and continue to be broken today - but that’s not the main argument I am attempting to present. My argument is that, if everyone has the right to uphold opinions and impart views through any medium whatsoever, <i>then everyone has the legal right to spread misinformation and hatred</i>. 
</p>

<p>
    And that's what everyone is doing online and in meatspace - and that isn’t the problem. The problem is people are <i>believing</i>.
</p>


<h2>
    The Coming of the Apostate or, The Departure of Sanity: Freedom of Expression & Cracks in Canonical Law
</h2>

<div class="quotebox">
    <h3 class="quote">
        “The Apostate is coming […] believe in Christ.”
        <h4>
            - Youtube spam-comment(s) by an Autonomous Bot
        </h4>
        <h3>
            [ This quotation is not used as an attack on the Christian faith ]
        </h3>
    </h3>
</div>


<h2>
    Freedom of Speech
</h2>

<p>
    Even before the problems I am about to lay forward were drawn up in research institutes all over the world, there was (and still is) a lot of turmoil on The Internet.
</p>

<p>
    Unintended (people who genuinely believe the doctrine they are spreading) or Intended Lies (‘Internet Trolls’ and meme culture) permeated and still do spread on Humanities’ biggest store of information: Authority is lying to you; America has a moral/divine right to interfere in other countries if needed; socialism works; the Earth is flat; humanity never went to space. These, and a great deal more. 
</p>

<p>
    Lies circulate on the internet because anyone who has a reliable internet connection can post their views on things - on Youtube, GoodReads and Amazon reviews, News, Reddit threads, discussion forums, Wikipedia articles, even - and increasingly people are doing just that.
</p>

<p>
    Rage, disputes, righteous battles and ‘debates’ run through the Internet, lacing social media platforms with die-hard Left/Right-Wing armchair activists, all giving opinions on topics they have no knowledge of - ranging from people denouncing all religions save theirs as being “violent cults that should be eradicated” to people with no knowledge whatsoever of bureaucratic procedures recommending “AIs are sentient and we should give them rights before it’s too late!”  
</p>

<p>
    At a joint hearing before senators on the Commerce and Judiciary committees, a senator asked Mark Zuckerburg, co-founder of the social media website Facebook and its parent company Meta Platforms, regarding the posting of misinformation onMeta’s social media platforms, “So you won’t take down lies?” 
</p>

<p>
    Apparently, The <i>Freedom of Expression Act</i> says No, you cannot legally take down someone's ‘opinion’, no matter how outlandish their claim is. Besides, who is Mark Zuckerburg to listen to when he sets down the parameters for a censorship algorithm? The US Government, with its divided opinions? His own beliefs, leading to a social media scandal? Religious Scripture? Harvard Philosophers, maybe?
</p>

<p>
    Freedom of Speech doesn’t and, at the same, <i>does</i> exist. You have the legal right to burn scripture to stir hatred in Denmark, but no right to say that a nation may have committed war crimes in such or such country - Freedom of Speech is, ironically, a picky bit of canonical law. Perhaps the most fickle law of all.
</p>

<p>
    Freedom of Speech and the Freedom of Spreading Beliefs are laws that frequently clash heavily with basic human ethics: does a man have the right to promote [for example] racism and hatred because it is justified in the <i>Freedom of Expression Act</i>? 
</p>

<p>
    Freedom of Speech is a beautiful and poetic law in theory, but in practice, it falls apart, because no matter what you try, not all peoples’ are rational, and the peaceful representation of every human belief and culture in a single nation is an impossibility and an insult to the principles of Game Theory.
</p>

<p>
    For example, let’s say some government decides to stipulate in its Laws that Freedom of Expression is allowed unless said Expression is designed to spread ‘misinformation’. Let’s assume, for the sake of Academia, that this very <i>human</i> government does not exploit this law for personal benefit, who is to decide what ‘misinformation’ is? Does claiming [for example] that the military intervention by the US in Third-World Countries is a cover-up for strategic resource exploitation [or vice versa] count as ‘misinformation’? Or what about the Flat-Earthers? They undoubtedly believe in their theology, but should their beliefs be wiped from FaceBook all the same? 
</p>

<p>
    Freedom of Speech can work for you, but just as easily, work against you. And on the Internet, with ‘Truthers’ hidden behind social media accounts, complete Freedom of Expression is damaging, not freeing, and solving this problem requires huge protocol overhauls and a large quantity of ethical, legal and philosophical debate that may never reach a conclusive answer. 
</p>

<h2>
    Intellectual Faeces and Quality Control
</h2>

<p>
    To put it bluntly: why did this happen? Where did it all go wrong? How did such a revolutionary invention as the Internet end up in this state? 
</p>

<p>
    The answer has a lot to do with ‘quality control.’ When the Internet was invented, a thing no one foresaw was the sheer amount of opinions and information that would end up dumped in. 
For example, in the old days, when a person required information, that information was usually found in books, and since the publication of a book required some level of expertise and an informal form of peer review, there was some assurance as to the reliability of the information/opinion made public.
</p>

<p>
    Today, things are different: anybody can say anything, and he who shouts the loudest and the most incoherently, climbs the Internet’s algorithmically-calculated ranks. Besides that, now that anyone with an internet connection can type their thoughts in, you also have uneducated people in LDCs making solecism-laced claims, adding mortar shells to an already thunderous salvo.
</p>

<p>
    Besides the Internet's quality being in jeopardy, self-publishing has flooded the market with books making outlandish claims to gain attention. Carefully researched, thoughtfully argued information is drowning in the intellectual faeces of the information age. 
</p>

<p>
    Those people who look critically and passionately for reliable, quality information will find it. Those too lazy to do so will end up less informed.
</p>

<p>
    And, as years of cognitive research have shown, humans prefer what comes easy.
</p>

<h2>
    Anything, Anyone, Anywhere, Anytime:  deepfakes, Hoodwinking Themis, Fracturing Realities & When Governments Lie
</h2>

<div class="quotebox">
    <h3 class="quote">
        “May you live in interesting times” <h4>- Source Disputed</h4>
    </h3>
</div>

<h2>
    Deepfakes 
</h2>

<p>
    Deepfakes are hyper-realistic digital forgeries - such as images or videos - created by machine learning techniques that portray various people in events that never actually occurred or participated in and are created without their consent or knowledge.
</p>

<p>
    To appreciate the problem of deepfakes - yes, it’s a problem - you need to understand how deepfakes work and how they are designed. 
</p>

<p>
    Two AIs, the Detective and the Forger, work in tandem to produce a deepfake. The Forger-AI creates the requested image and sends it to the Detective-AI [which has been trained on hundreds, sometimes thousands of images of exactly what the finished product should be like] to check for any discrepancies. If the Detective finds inaccuracies it informs the Forger, which goes back and tries again, and again, looping around and perfecting the deepfake further. And so the longer you leave the two AIs in the creation loop, the better the resulting deepfake will be.
</p>

<p>
    There are several methods for designing deepfakes, but the most common one is this.
</p>

<p>
    And you should know the other crucial thing that’s needed for creating a high-quality deepfake of a person: you need images and videos of the victim - just a decent amount of data, nothing fancy, nothing preposterously large.
</p>

<p>
    This means that, for now, creating deepfakes is limited to people like celebrities and, more alarmingly, politicians. Oh, and anybody who has posted too many pictures of themselves on social media platforms, uploading all sorts of data that could be exploited to tailor a deepfake. They, too.
</p>

<p>
    And deepfakes are getting good - so good that they cause even Interview Editors, people who spent years and hundreds of hours working with human faces, pinpointing imperfections in digital recordings of said faces, to start second guessing themselves when encountering a deepfake.
</p>

<p>
    The problem posed by deepfakes is a classic Doom & Gloom situation: imagine that in this decade, now that almost anyone with simple programming knowledge and a stable internet connection - and if someone invests in this particular technology [as people are already doing and are likely to keep doing] and makes the process even smoother by putting an intuitive UI on the whole thing, anyone with just a stable internet connection - can create deepfakes, flooding the Internet with these high-quality synthetic recordings of events that never happened. 
</p>

<p>
    Now, imagine this: with people online and in the real world already fractured over what they believe - no matter how much evidence is presented or not presented - videos start to emerge of events that never really happened: attacks that never took place, political scandals that never occurred, incriminating evidence of implicating innocent people in crimes they never committed. And now that people can’t decide what to believe and what not to believe [or don’t want to believe, and vice versa] - you have an information apocalypse.    
</p>

<p>
    To begin with, incriminating audio and visual evidence [particularly audio] will carry less weight from now on and will cause all hell to break loose inside the courts of justice, making procuring rightful or wrong convictions fiendishly difficult.

</p>

<p>
    It is now possible to deepfake security tapes to frame people and, more easily, create synthetic recordings of voices. 
</p>

<p>
    Cybercrime can now run rampant - with criminals masquerading as relatives [using deepfake digital masks that change their appearances and doctored audio recordings] to purloin sensitive data and thieve money. 
    And then there are the governments who may decide to dabble in the technology to discredit and discredit extremist groups and foreign enemies. This may even be used as an effective means to contact targeted individuals.

</p>

<p>
    The software is free, it’s effective, and it’s easy to use - and people are using it already: a deepfake audio recording was used in a UK child custody battle in an effort to discredit a Dubai resident in 2020, with the mother using simple online software and tutorials to doctor the recording.

And that was in 2020. The technology has come a long way since.

</p>

<p>
    There’s even a California-based VFX studio named <i>Deep Voodoo</i> that specialises in creating deepfake films, movies and videos, founded by the popular deepfake Youtuber-Artist Ctrl Shift Face.  

</p>

<p>
    But why don’t we simply create a detection method for deepfakes? Well, we have: a recent scientific paper looked into using biological signals from the face as a nearly ironclad [98% reliability] way to test the authenticity of a recording. Another method - more popularly used by the Pentagon - uses AI to analyse Deecpfakes and decide on their authenticity. 

</p>

<p>
    But here’s the catch: the people synthesising these deepfakes can simply take the parameters of these detection algorithms into account when designing and perfecting future synthetic videos [remember the Forger-Detective method for deepfake synthesis?] 

</p>

<p>
    Even if, say, the NSA or the CIA or some other intelligence agency comes up with a foolproof detection method for deepfakes, they will have to widely publicised so the public and the Low-courts can use them too, which will just provide deepfake creators more data to perfect their creations, leading to an infinite loop of mass-detection followed, eventually, by even better deepfakes which will end only if a truly unbreakable detection method is innovated. 

</p>

<p>
    And <i>if</i> they decide not to release their detection methods and use them for themselves, then the public - as countercultural as ever - will claim that the government is lying when they denounce some audiovisual piece of ‘evidence’ as a deepfake and demand proof - proof that the government cannot release after every deepfake if they want a chance of detecting the next one that will inevitably be knocking on the New York office doors of their lawyers-in-arms.
</p>

<p>
    And there's a good percentage of people - the cream of the ‘Truthist’ crop, yes, but still a good amount, both in DCs and LDCs - who prefer to choose what and what not to believe and absolutely will not change their views.

</p>

<p>
    
 Deepfakes may solidify ignorance but not help combat it.

 We have never had an entirely informed public in any nation - DC or otherwise 
 
</p>

<h2>
    Large Scale Internet Hoaxes 
</h2>

<p>
    In 1962, during the coldest depths of the Cold War, a report was drafted by top American Military officials, in which they elaborated on detailed plans for a false flag operation that included blowing up US Ships, fake hijacking attempts, lobbing mortars on American soil and running a [small and widely publicised] terror campaign within America before placing the blame on Cuba to garner support for a military invasion of the island.
</p>

<p>
    This plan - known as Operation Northwood - was never put into effect [just one man, John F. Kennedy, vetoed it] but this particular story is interesting in the overall scope of this article because it provides a precedent on why a government or entity with sufficient funds may decide to plan and execute large scale hoaxes to garner support for geopolitical or socioeconomic goals today [after all, little has changed in the overall operation of the military machine.]
</p>

<p>
    Putting aside past major events that conspiracy theorists point to as possible examples of such large-scale hoaxes [the horrific events of <i>9/11</i> being the most prominent] I predict that, in the next decade, we will see a plethora of [large-scale] hoaxes created by powerful entities such as governments, oligarchs and even small teams with their own agenda [‘Trolling’, for example.]  
</p>

<p>
    Of course, nothing was stopping someone with the means from implementing these theorised, large-scale hoaxes in the past, but it’s become easier now - almost childishly so for some wealthy figures - to do something like this.

</p>

<p>
    You can hire part-time actors [paid anonymously by cryptocurrencies] and have them enact war footage of an invasion that never took place. You can have a CGI house in Malaysia synthesise footage of nuclear blasts. You can crush the networks of an entire nation under DDoS attacks to prove the authenticity of these supposed attacks. You can, now that we have deepfakes, create fake footage of politicians and leaders of militaries  giving commands or doing illegal acts to sow confusion in politically-delicate times [elections, for example] and during times when reliable communication is critical [military operations during times of war.] 
</p>

<p>
    A well-pulled-off hoax, such as, for example, an unfair declaration of martial law in a state, by using DDoS attacks, CGI footage, actors and bots spreading the false news across the internet [all of this possible using current technology] could cause enough confusion and rage on the Internet for the rest of the country to dissolve in riots and protests.

</p>

<p>
    And, since even big journalism outlets use social media to locate what passes for news these days, it would be easy to have people not usually susceptible to outlandish claims believe in such a hoax for an extended period of time - a day, perhaps even a week, long enough to cause devastating damage.

</p>

<h2>
    Subjective Reality or, Philosophical Implications 

</h2>

<p>
    In 2018, during the earliest stages of deepfake technology development, a US Congressman sent a letter to the US Director of National Intelligence raising the alarm on deepfakes, saying ‘By blurring the line between fact and fiction, deepfake technology could undermine public trust in recorded images and videos as objective depictions of reality.
</p>

<p>
    Even before these generative AIs evolved to the stage where government officials decided to make their unease known, people were living separate realities: some people believed that certain terrorist attacks were coordinated by people in government, others believed differently, some people believed that the Earth was flat, some people believed that space beyond the sky didn’t exist.

</p>

<p>
    They were living in separate realities because, after all, how can reality be different from what you perceive it to be inside your mind?
</p>

<p>
    Fiction is spreading on the internet, and it will continue to spread and grow worse, as deepfake videos and audio recordings start spreading across the Internet, the religiously-radical and extremist side of the Internet will slowly grow as people begin to believe much of what is on the Internet without objective analysing, fueled by the increase of the general amount of misinformation pumping through the great digital super-structure.
</p>

<p>
    <i>This</i> is what the Fall of The Internet looks like.
</p>

<h2>
    Implications for Government & Law
</h2>

<p>
    If my predictions do come true, then we may see a Seattle-type situation in the US, with voters with radical or particularly strong views flooding the elections. This may lead to large extremist sects and radical activists winning positions of power in democratic governments as their supporters grow, hyped on the flood of misinformation plaguing the Internet.

</p>

<p>
    Riots may rumble across nations as hatred and strife between social divisions grow larger and fake information [either targeted disinformation campaigns by foreign actors or domestic by-products of already available misinformation] and large-scale disagreements cause anger to erupt on both sides in an ideological war against all but your own ideological partners.
</p>

<p>
    Ironically, the countries most safe from domestic turmoil will be the ones in which cybersecurity is a norm i.e. the nations which do not allow complete Freedom of Speech and are vigilant and active in blocking nefarious websites and outlawing means around cyber laws. Additionally, the countries in which the general public does not have access to weapons will be easier to control should the need arise.

</p>

<p>
    A nation in which terrorist or extremist groups have even a say in official rule and a large fraction of public support would indeed be a terrifying world to live in.
</p>

<h2>
    Unflattening the Earth: The Encyclopedia Disinformatica, Pruning Truth(ists) & Social Media Algorithms     

</h2>

<div class="quotebox">
    <h4 class="quote">
        “Tell a lie once and all your truths become questionable.” <h3>- Unknown</h3>
    </h4>
</div>

<p>
    As events heat up and the Internet is slowly demolished, several solutions are proposed to help solve this crisis.
</p>

<p>
    The first one, simply, is to have a silicon valley softworks firm create editing software i.e software that edits out any content that a person does not wish to see - for example, if a person has no interest in seeing spam comments on the scripture of a particular religion, then the overlay filter will edit the stuff out of the persons feed. Of course, this will be, engineering-wise, a very difficult task to do as the parameters of such algorithms will have to be pressure-tight and require large-scale implementation, from Amazon reviews to Youtube comments, but it will nonetheless be possible. 

</p>

<p>
    There’s a problem with this solution, however - <i>people who are already ignorant may simply become more ignorant</i>. For example, people who block out leftist information will simply become more right-wing, and vice versa [it can be argued, however, that this is already happening by way of social media and entertainment algorithms.]

</p>

<p>
    Besides, this isn’t a solution to the problem - merely a way of stopping the problem from affecting people’s everyday use of the Internet.

Long-term and effective solutions proposed in the way of solving the problem include certain large-scale education programs. [For my thoughts on these solutions refer back to this article's section on Freedom of Speech.]

</p>

<p>
    Another, slightly reckless solution to this problem, was suggested in the 1990s by security researcher Matt Blaze, who talked about a certain <i>“Encyclopedia Disinformatica”</i>, which author Neal Stephenson described as  "a sort of fake Wikipedia containing plausible-sounding but deliberately false information as a way of sending the message to people that they shouldn't just believe everything that they see on the internet."

</p>

<h2>
    Final Thoughts
</h2>

<p>
    The best way to stop misinformation is to look things up well before you pass them on. Be humble when you communicate and always educate, not judge. Treat others' ideologies as you would want your own treated. If you can’t change someone, then part on good terms to talk another day.
</p>

<h2>Bibliography</h2>

<ul>
    <li><a target="_blank" href="https://journals.sagepub.com/doi/abs/10.1177/14614448211019198">Navigating the maze: Deepfakes, cognitive ability, and social media news skepticism.</a> - Ahmed, S.</li>
    <li><a target="_blank" href="https://www.hindawi.com/journals/scn/2021/6626974/">Countering Spoof: Towards Detecting Deepfake with Multidimensional Biological Signals.</a> - Beijing Chen.</li>
    <li><a target="_blank" href="https://journals.sagepub.com/doi/full/10.1177/1940161220944364">Do (Microtargeted) Deepfakes Have Real Effects on Political Attitudes?</a> - Dobber, T., Metoui, N., Trilling, D., Helberger, N., & Vreese, C. d.</li>
    <li><a target="_blank" href="https://journals.sagepub.com/doi/full/10.1177/0963721417718261">The Psychology of Conspiracy Theories.</a> - Douglas, K. M., Sutton, R. M., & Cichocka, A.</li>
    <li><a target="_blank" href="https://onlinelibrary.wiley.com/doi/full/10.1111/pops.12568">Understanding Conspiracy Theories.</a> - Douglas, K. M., Uscinski, J. E., Sutton, R. M., Cichocka, A., Nefes, T., Ang, C. S., & Deravi, F.</li>
    <li><a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/9123958/authors#authors">Artificial Intelligence in Digital Media: The Era of Deepfakes.</a> - Karnouskos, S.</li>
    <li><a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/8638330">Exploiting Visual Artifacts to Expose Deepfakes and Face Manipulations.</a> - Matern, F., Riess, C., & Stamminger, M.</li>
    <li><a target="_blank" href="https://www.tandfonline.com/doi/abs/10.1080/21670811.2022.2026797">The Effect of Deepfake Video on News Credibility and Corrective Influence of Cost-Based Knowledge about Deepfakes.</a> - Shin, S. Y., & Lee, J.</li>
    <li><a target="_blank" href="https://www.un.org/en/about-us/universal-declaration-of-human-rights">Universal Declaration of Human Rights.</a> - United Nations.</li>
    <li><a target="_blank" href="https://journals.sagepub.com/doi/full/10.1177/2056305120903408">Deepfakes and Disinformation: Exploring the Impact of Synthetic Political Video on Deception, Uncertainty, and Trust in News.</a> - Vaccari, C., & Chadwick, A.</li>
    <li>Audiovisual Resource: <a target="_blank" href="https://www.youtube.com/watch?v=S951cdansBI">"Deep Fakes are About to Change Everything"</a> - Johnny Harris.</li>
</ul>
</div>